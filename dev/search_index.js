var documenterSearchIndex = {"docs":
[{"location":"similarities/#Similarity-functions-1","page":"Similarity functions","title":"Similarity functions","text":"","category":"section"},{"location":"similarities/#Cosine-similarity-1","page":"Similarity functions","title":"Cosine similarity","text":"","category":"section"},{"location":"similarities/#","page":"Similarity functions","title":"Similarity functions","text":"cossim","category":"page"},{"location":"similarities/#LSH.cossim","page":"Similarity functions","title":"LSH.cossim","text":"cossim(x,y)\n\nComputes the cosine similarity between two inputs x and y. Cosine similarity is defined as\n\ntextcossim(xy) = fracleftlangle xyrightranglexcdoty\n\nwhere leftlanglecdotcdotrightrangle is an inner product (e.g. dot product) and cdot is its derived norm. This is roughly interpreted as being related to the angle between the inputs x and y: when x and y have low angle between them, cossim(x,y) is high (close to 1). When x and y have large angle between them, cossim(x,y) is low (close to -1).\n\nArguments\n\nx and y: two inputs for which dot(x,y), norm(x), and norm(y) are defined.\n\nExamples\n\njulia> using LinearAlgebra: dot, norm;\n\njulia> x, y = rand(4), rand(4);\n\njulia> cossim(x,y) == dot(x,y) / (norm(x) * norm(y))\ntrue\n\njulia> z = rand(5);\n\njulia> cossim(x,z)\nERROR: DimensionMismatch(\"dot product arguments have lengths 4 and 5\")\n\nSee also: SimHash\n\n\n\n\n\n","category":"function"},{"location":"similarities/#\\ellp-and-Lp-distance-1","page":"Similarity functions","title":"ell^p and L^p distance","text":"","category":"section"},{"location":"similarities/#","page":"Similarity functions","title":"Similarity functions","text":"ℓp","category":"page"},{"location":"similarities/#LSH.ℓp","page":"Similarity functions","title":"LSH.ℓp","text":"ℓp(x::AbstractVector, y::AbstractVector, p::Real)\nℓ1(x::AbstractVector, y::AbstractVector)\nℓ2(x::AbstractVector, y::AbstractVector)\n\nComputes the ell^p distance between a pair of vectors, given by\n\nell^p(xy) coloneqq x - y_p = left(sum_i leftx_i - y_iright^pright)^1p\n\nℓ1(x,y) is the same as ℓp(x,y,1), and ℓ2(x,y) is the same as ℓp(x,y,2).\n\nExamples\n\njulia> x = [1, 2, 3];\n\njulia> y = [4, 5, 6];\n\njulia> ℓp(x,y,2) == (abs(1-4)^2 + abs(2-5)^2 + abs(3-6)^2)^(1/2)\ntrue\n\njulia> ℓp(x,y,3) == (abs(1-4)^3 + abs(2-5)^3 + abs(3-6)^3)^(1/3)\ntrue\n\nSee also: ℓp_norm\n\n\n\n\n\n","category":"function"},{"location":"similarities/#","page":"Similarity functions","title":"Similarity functions","text":"Lp","category":"page"},{"location":"similarities/#LSH.Lp","page":"Similarity functions","title":"LSH.Lp","text":"Lp(x::AbstractVector, y::AbstractVector, p::Real)\nL1(x::AbstractVector, y::AbstractVector)\nL2(x::AbstractVector, y::AbstractVector)\n\nComputes the ℓ^p distance between a pair of vectors x and y. Identical to ℓp(x,y,p), ℓ1(x,y), and ℓ2(x,y), respectively.\n\n\n\n\n\nLp(f, g, interval::LSH.RealInterval, p)\nL1(f, g, interval::LSH.RealInterval)\nL2(f, g, interval::LSH.RealInterval)\n\nComputes the L^p distance between two functions, given by\n\nL^p(fg) coloneqq f - g_p = left(int_a^b leftf(x) - g(x)right^p hspace015cm dxright)^1p\n\nExamples\n\nBelow we compute the L^1, L^2, and L^3 distances between f(x) = x^2 + 1 and g(x) = 2x over the interval 01. The distances are computed by evaluating the integral\n\nleft(int_0^1 leftf(x) - g(x)right^p hspace015cmdxright)^1p = left(int_0^1 leftx^2 - 2x + 1right^p hspace015cmdxright)^1p = left(int_0^1 (x - 1)^2p hspace015cmdxright)^1p\n\nfor p = 1, p = 2, and p = 3.\n\njulia> f(x) = x^2 + 1; g(x) = 2x;\n\njulia> interval = LSH.@interval(0 ≤ x ≤ 1);\n\njulia> Lp(f, g, interval, 1) ≈ L1(f, g, interval) ≈ 3^(-1)\ntrue\n\njulia> Lp(f, g, interval, 2) ≈ L2(f, g, interval) ≈ 5^(-1/2)\ntrue\n\njulia> Lp(f, g, interval, 3) ≈ 7^(-1/3)\ntrue\n\nSee also: Lp_norm, ℓp\n\n\n\n\n\n","category":"function"},{"location":"similarities/#Jaccard-similarity-1","page":"Similarity functions","title":"Jaccard similarity","text":"","category":"section"},{"location":"similarities/#","page":"Similarity functions","title":"Similarity functions","text":"jaccard","category":"page"},{"location":"similarities/#LSH.jaccard","page":"Similarity functions","title":"LSH.jaccard","text":"jaccard(A::Set, B::Set) :: Float64\n\nComputes the Jaccard similarity between sets A and B, which is defined as\n\ntextJaccard(AB) = fracleftA cap BrightleftA cup Bright\n\nArguments\n\nA::Set, B::Set: the two sets with which to compute Jaccard similarity.\n\nReturns\n\nFloat64: the Jaccard similarity between sets A and B, which is between 0 and 1.\n\nExamples\n\njulia> A, B = Set([1, 2, 3]), Set([2, 3, 4]);\n\njulia> jaccard(A,B)\n0.5\n\njulia> jaccard(A,B) == length(A ∩ B) / length(A ∪ B)\ntrue\n\nSee also: MinHash\n\n\n\n\n\n","category":"function"},{"location":"similarities/#Inner-product-1","page":"Similarity functions","title":"Inner product","text":"","category":"section"},{"location":"similarities/#","page":"Similarity functions","title":"Similarity functions","text":"inner_prod","category":"page"},{"location":"similarities/#LSH.inner_prod","page":"Similarity functions","title":"LSH.inner_prod","text":"inner_prod(x::AbstractVector, y::AbstractVector)\n\nComputes the ell^2 inner product (dot product)\n\nleftlangle x yrightrangle = sum_i x_iy_i\n\nExamples\n\njulia> using LinearAlgebra: dot;\n\njulia> x, y = randn(4), randn(4);\n\njulia> inner_prod(x,y) ≈ dot(x,y)\ntrue\n\n\n\n\n\ninner_prod(f, g, interval::LSH.RealInterval)\n\nComputes the L^2 inner product\n\nleftlangle f grightrangle = int_a^b f(x)g(x) hspace015cm dx\n\nwhere the interval we're integrating over is specified by the interval argument.\n\nExamples\n\njulia> f(x) = cos(x); g(x) = sin(x);\n\njulia> inner_prod(f, g, LSH.@interval(0 ≤ x ≤ π/2)) ≈ 1/2\ntrue\n\n\n\n\n\n","category":"function"},{"location":"#LSH.jl-1","page":"Home","title":"LSH.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"LSH.jl is a Julia package for performing locality-sensitive hashing with various similarity functions.","category":"page"},{"location":"#Introduction-1","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"One of the simplest methods for classifying, categorizing, and grouping data is to measure how similarities pairs of data points are. For instance, the classical k-nearest neighbors algorithm takes a similarity function","category":"page"},{"location":"#","page":"Home","title":"Home","text":"sXtimes XtomathbbR","category":"page"},{"location":"#","page":"Home","title":"Home","text":"and a query point xin X, where X is the input space. It then computes s(xy) for every point y in a database, and keeps the k points that are closest to x.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Broadly, there are two computational issues with this approach:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"First, the database may be massive, much larger than could possibly fit in memory. This would make the brute-force approach of computing s(xy) for every point y in the database far too expensive to be practical.\nSecond, the dimensionality of the data may be such that computing s(xy) is itself expensive. In addition, the similarity function itself may simply be intrinsically difficult to compute. For instance, calculating Wasserstein distance entails solving a very high-dimensional linear program.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In order to solve these problems, researchers have over time developed a variety of techniques to accelerate similarity search:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"k-d trees\nBall trees\nData reduction techniques","category":"page"},{"location":"#Locality-sensitive-hashing-1","page":"Home","title":"Locality-sensitive hashing","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Locality-sensitive hashing (LSH) is a technique for accelerating similarity search that works by using a hash function on the query point x and limiting similarity search to only those points in the database that experience a hash collision with x. The hash functions that are used are randomly generated from a family of locality-sensitive hash functions. These hash functions have the property that Prh(x) = h(y) (i.e., the probability of a hash collision) increases the more similar that x and y are.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"LSH.jl is a package that provides definitions of locality-sensitive hash functions for a variety of different similarities. Currently, LSH.jl supports hash functions for","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Cosine similarity (cossim)\nJaccard similarity (jaccard)\nL^1 (Manhattan / \"taxicab\") distance (ℓ1)\nL^2 (Euclidean) distance (ℓ2)\nInner product (inner_prod)\nFunction-space hashes (L1, L2, and cossim)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"","category":"page"}]
}
