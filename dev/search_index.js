var documenterSearchIndex = {"docs":
[{"location":"#LSH.jl-1","page":"Home","title":"LSH.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"LSH.jl is a Julia package for performing locality-sensitive hashing with various similarity functions.","category":"page"},{"location":"#Introduction-1","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"One of the simplest methods for classifying, categorizing, and grouping data is to measure how similarities pairs of data points are. For instance, the classical k-nearest neighbors algorithm takes a similarity function","category":"page"},{"location":"#","page":"Home","title":"Home","text":"sXtimes XtomathbbR","category":"page"},{"location":"#","page":"Home","title":"Home","text":"and a query point xin X, where X is the input space. It then computes s(xy) for every point y in a database, and keeps the k points that are closest to x.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Broadly, there are two computational issues with this approach:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"First, the database may be massive, much larger than could possibly fit in memory. This would make the brute-force approach of computing s(xy) for every point y in the database far too expensive to be practical.\nSecond, the dimensionality of the data may be such that computing s(xy) is itself expensive. In addition, the similarity function itself may simply be intrinsically difficult to compute. For instance, calculating Wasserstein distance entails solving a very high-dimensional linear program.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In order to solve these problems, researchers have over time developed a variety of techniques to accelerate similarity search:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"k-d trees\nBall trees\nData reduction techniques","category":"page"},{"location":"#Locality-sensitive-hashing-1","page":"Home","title":"Locality-sensitive hashing","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Locality-sensitive hashing (LSH) is a technique for accelerating similarity search that works by using a hash function on the query point x and limiting similarity search to only those points in the database that experience a hash collision with x. The hash functions that are used are randomly generated from a family of locality-sensitive hash functions. These hash functions have the property that Prh(x) = h(y) (i.e., the probability of a hash collision) increases the more similar that x and y are.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"LSH.jl is a package that provides definitions of locality-sensitive hash functions for a variety of different similarities. Currently, LSH.jl supports hash functions for","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Cosine similarity (cossim)\nJaccard similarity (jaccard)\nL^1 (Manhattan / \"taxicab\") distance (ℓ1)\nL^2 (Euclidean) distance (ℓ2)\nInner product (inner_prod)\nFunction-space hashes (L1, L2, and cossim)","category":"page"}]
}
